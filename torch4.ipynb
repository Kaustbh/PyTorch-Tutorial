{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Advance House Price Prediction using PyTorch- Tabular dataset\n",
    "\n",
    "https://docs.fast.ai/tabular.html https://www.fast.ai/2018/04/29/categorical-embeddings/ https://www.fast.ai/2018/04/29/categorical-embeddings/ https://yashuseth.blog/2018/07/22/pytorch-neural-network-for-tabular-data-with-categorical-embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('houseprice.csv',usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
    "                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12665</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1133</td>\n",
       "      <td>1349</td>\n",
       "      <td>281213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>120</td>\n",
       "      <td>RM</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4435</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2004</td>\n",
       "      <td>848</td>\n",
       "      <td>0</td>\n",
       "      <td>155900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8562</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1957</td>\n",
       "      <td>1526</td>\n",
       "      <td>0</td>\n",
       "      <td>144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1948</td>\n",
       "      <td>972</td>\n",
       "      <td>0</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>86.0</td>\n",
       "      <td>11500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1936</td>\n",
       "      <td>1020</td>\n",
       "      <td>1037</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>79.0</td>\n",
       "      <td>12420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2001</td>\n",
       "      <td>944</td>\n",
       "      <td>896</td>\n",
       "      <td>230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5436</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1922</td>\n",
       "      <td>796</td>\n",
       "      <td>358</td>\n",
       "      <td>125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>70</td>\n",
       "      <td>RM</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1920</td>\n",
       "      <td>832</td>\n",
       "      <td>650</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10434</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1955</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6040</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1955</td>\n",
       "      <td>1152</td>\n",
       "      <td>0</td>\n",
       "      <td>82000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  ...  1stFlrSF 2ndFlrSF SalePrice\n",
       "1395          60       RL         88.0  ...      1133     1349    281213\n",
       "1078         120       RM         37.0  ...       848        0    155900\n",
       "1053          20       RL         68.0  ...      1526        0    144500\n",
       "311           20       RL         50.0  ...       972        0    132000\n",
       "907           50       RL         86.0  ...      1020     1037    250000\n",
       "1410          60       RL         79.0  ...       944      896    230000\n",
       "1385          50       RM         40.0  ...       796      358    125500\n",
       "1149          70       RM         50.0  ...       832      650    143000\n",
       "1125          20       RL         60.0  ...      1005        0    115000\n",
       "39            90       RL         65.0  ...      1152        0     82000\n",
       "\n",
       "[10 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name MSSubClass and unique values are 15\n",
      "Column name MSZoning and unique values are 5\n",
      "Column name LotFrontage and unique values are 110\n",
      "Column name LotArea and unique values are 869\n",
      "Column name Street and unique values are 2\n",
      "Column name LotShape and unique values are 4\n",
      "Column name YearBuilt and unique values are 112\n",
      "Column name 1stFlrSF and unique values are 678\n",
      "Column name 2ndFlrSF and unique values are 368\n",
      "Column name SalePrice and unique values are 597\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(\"Column name {} and unique values are {}\".format(i,len(df[i].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Years']=datetime.datetime.now().year-df['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"YearBuilt\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=[\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]\n",
    "out_feature=\"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoders={}\n",
    "for feature in cat_features:\n",
    "    lbl_encoders[feature]=LabelEncoder()\n",
    "    df[feature]=lbl_encoders[feature].fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  ...  2ndFlrSF  SalePrice  Total Years\n",
       "0           5         3         65.0  ...       854     208500           21\n",
       "1           0         3         80.0  ...         0     181500           48\n",
       "2           5         3         68.0  ...       866     223500           23\n",
       "3           6         3         60.0  ...       756     140000          109\n",
       "4           5         3         84.0  ...      1053     250000           24\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [5, 3, 1, 0],\n",
       "       ...,\n",
       "       [6, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking and converting into tensors\n",
    "import numpy as np\n",
    "cat_features=np.stack([df['MSSubClass'], df['MSZoning'], df['Street'], df['LotShape']],1)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numpy to tensors\n",
    "import torch\n",
    "cat_features=torch.tensor(cat_features,dtype=torch.int64)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create continuous features\n",
    "cont_features=[]\n",
    "for i in df.columns:\n",
    "    if i in ['MSSubClass', 'MSZoning', 'Street', 'LotShape','SalePrice']:\n",
    "        pass\n",
    "    else:\n",
    "        cont_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total Years']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   65.,  8450.,   856.,   854.,    21.],\n",
       "        [   80.,  9600.,  1262.,     0.,    48.],\n",
       "        [   68., 11250.,   920.,   866.,    23.],\n",
       "        ...,\n",
       "        [   66.,  9042.,  1188.,  1152.,    83.],\n",
       "        [   68.,  9717.,  1078.,     0.,    74.],\n",
       "        [   75.,  9937.,  1256.,     0.,    59.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking continuous variables into tensors\n",
    "cont_values=np.stack([df[i].values for i in cont_features],axis=1)\n",
    "cont_values=torch.tensor(cont_values,dtype=torch.float)\n",
    "cont_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[208500.],\n",
       "        [181500.],\n",
       "        [223500.],\n",
       "        ...,\n",
       "        [266500.],\n",
       "        [142125.],\n",
       "        [147500.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependent feature\n",
    "y=torch.tensor(df['SalePrice'].values, dtype=torch.float).reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Size for Categorical Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['MSSubClass'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims = [len(df[col].unique()) for col in [\"MSSubClass\",\"MSZoning\",\"Street\",\"LotShape\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 5, 2, 4]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thumb Rule: Output dimension should be set based on input dimension(min(50,feature dimension//2))\n",
    "embedding_dim = [(x, min(50,(x+1)//2)) for x in cat_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 8), (5, 3), (2, 1), (4, 2)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(15, 8)\n",
       "  (1): Embedding(5, 3)\n",
       "  (2): Embedding(2, 1)\n",
       "  (3): Embedding(4, 2)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "embed_representation=nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
    "embed_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        [6, 3, 1, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_featuresz=cat_features[:4]\n",
    "cat_featuresz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',500)\n",
    "embedding_val=[]\n",
    "for i,e in enumerate(embed_representation):\n",
    "    embedding_val.append(e(cat_features[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.7053,  1.6639,  0.6774,  ...,  1.2852,  0.2202, -0.6388],\n",
       "         [-0.2177,  0.0288, -0.7971,  ...,  0.5431,  0.5801, -0.5142],\n",
       "         [ 0.7053,  1.6639,  0.6774,  ...,  1.2852,  0.2202, -0.6388],\n",
       "         ...,\n",
       "         [ 1.2890, -0.1303,  0.8250,  ...,  0.9110, -0.9025, -0.5493],\n",
       "         [-0.2177,  0.0288, -0.7971,  ...,  0.5431,  0.5801, -0.5142],\n",
       "         [-0.2177,  0.0288, -0.7971,  ...,  0.5431,  0.5801, -0.5142]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[1.9121, 1.5920, 1.9095],\n",
       "         [1.9121, 1.5920, 1.9095],\n",
       "         [1.9121, 1.5920, 1.9095],\n",
       "         ...,\n",
       "         [1.9121, 1.5920, 1.9095],\n",
       "         [1.9121, 1.5920, 1.9095],\n",
       "         [1.9121, 1.5920, 1.9095]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[1.9103],\n",
       "         [1.9103],\n",
       "         [1.9103],\n",
       "         ...,\n",
       "         [1.9103],\n",
       "         [1.9103],\n",
       "         [1.9103]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.3248,  0.6676],\n",
       "         [-0.3248,  0.6676],\n",
       "         [ 0.2395,  0.8146],\n",
       "         ...,\n",
       "         [-0.3248,  0.6676],\n",
       "         [-0.3248,  0.6676],\n",
       "         [-0.3248,  0.6676]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7053,  1.6639,  0.6774,  ...,  1.9103, -0.3248,  0.6676],\n",
       "        [-0.2177,  0.0288, -0.7971,  ...,  1.9103, -0.3248,  0.6676],\n",
       "        [ 0.7053,  1.6639,  0.6774,  ...,  1.9103,  0.2395,  0.8146],\n",
       "        ...,\n",
       "        [ 1.2890, -0.1303,  0.8250,  ...,  1.9103, -0.3248,  0.6676],\n",
       "        [-0.2177,  0.0288, -0.7971,  ...,  1.9103, -0.3248,  0.6676],\n",
       "        [-0.2177,  0.0288, -0.7971,  ...,  1.9103, -0.3248,  0.6676]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating the embeddings based on rows\n",
    "z=torch.cat(embedding_val,1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Dropout\n",
    "dropout=nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1755,  0.0000,  1.1290,  ...,  3.1838, -0.5414,  0.0000],\n",
       "        [-0.0000,  0.0480, -1.3284,  ...,  3.1838, -0.5414,  0.0000],\n",
       "        [ 1.1755,  0.0000,  1.1290,  ...,  3.1838,  0.3992,  1.3577],\n",
       "        ...,\n",
       "        [ 2.1484, -0.2172,  0.0000,  ...,  3.1838, -0.5414,  0.0000],\n",
       "        [-0.3629,  0.0000, -1.3284,  ...,  3.1838, -0.0000,  1.1126],\n",
       "        [-0.3629,  0.0000, -0.0000,  ...,  3.1838, -0.0000,  0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embed=dropout(z)\n",
    "final_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create a Feed Forward Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class FeedForwardNN(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((out for inp,out in embedding_dim))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "model=FeedForwardNN(embedding_dim,len(cont_features),1,[100,50],p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.4, inplace=False)\n",
       "  (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.4, inplace=False)\n",
       "  (8): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   65.,  8450.,   856.,   854.,    21.],\n",
       "        [   80.,  9600.,  1262.,     0.,    48.],\n",
       "        [   68., 11250.,   920.,   866.,    23.],\n",
       "        ...,\n",
       "        [   66.,  9042.,  1188.,  1152.,    83.],\n",
       "        [   68.,  9717.,  1078.,     0.,    74.],\n",
       "        [   75.,  9937.,  1256.,     0.,    59.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1200\n",
    "test_size=int(batch_size*0.15)\n",
    "train_categorical=cat_features[:batch_size-test_size]\n",
    "test_categorical=cat_features[batch_size-test_size:batch_size]\n",
    "train_cont=cont_values[:batch_size-test_size]\n",
    "test_cont=cont_values[batch_size-test_size:batch_size]\n",
    "y_train=y[:batch_size-test_size]\n",
    "y_test=y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 180, 1020, 180, 1020)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_categorical),len(test_categorical),len(train_cont),len(test_cont),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 and the loss: 200496.75\n",
      "Epoch number: 11 and the loss: 200493.46875\n",
      "Epoch number: 21 and the loss: 200489.140625\n",
      "Epoch number: 31 and the loss: 200482.625\n",
      "Epoch number: 41 and the loss: 200473.234375\n",
      "Epoch number: 51 and the loss: 200461.375\n",
      "Epoch number: 61 and the loss: 200446.421875\n",
      "Epoch number: 71 and the loss: 200429.359375\n",
      "Epoch number: 81 and the loss: 200407.953125\n",
      "Epoch number: 91 and the loss: 200383.390625\n",
      "Epoch number: 101 and the loss: 200355.28125\n",
      "Epoch number: 111 and the loss: 200322.140625\n",
      "Epoch number: 121 and the loss: 200291.109375\n",
      "Epoch number: 131 and the loss: 200252.109375\n",
      "Epoch number: 141 and the loss: 200206.4375\n",
      "Epoch number: 151 and the loss: 200163.390625\n",
      "Epoch number: 161 and the loss: 200112.140625\n",
      "Epoch number: 171 and the loss: 200059.203125\n",
      "Epoch number: 181 and the loss: 200006.640625\n",
      "Epoch number: 191 and the loss: 199948.140625\n",
      "Epoch number: 201 and the loss: 199881.234375\n",
      "Epoch number: 211 and the loss: 199815.703125\n",
      "Epoch number: 221 and the loss: 199737.71875\n",
      "Epoch number: 231 and the loss: 199669.0625\n",
      "Epoch number: 241 and the loss: 199588.046875\n",
      "Epoch number: 251 and the loss: 199506.046875\n",
      "Epoch number: 261 and the loss: 199408.734375\n",
      "Epoch number: 271 and the loss: 199324.203125\n",
      "Epoch number: 281 and the loss: 199243.25\n",
      "Epoch number: 291 and the loss: 199138.640625\n",
      "Epoch number: 301 and the loss: 199027.453125\n",
      "Epoch number: 311 and the loss: 198929.75\n",
      "Epoch number: 321 and the loss: 198852.578125\n",
      "Epoch number: 331 and the loss: 198698.4375\n",
      "Epoch number: 341 and the loss: 198605.03125\n",
      "Epoch number: 351 and the loss: 198493.578125\n",
      "Epoch number: 361 and the loss: 198389.5625\n",
      "Epoch number: 371 and the loss: 198243.421875\n",
      "Epoch number: 381 and the loss: 198106.265625\n",
      "Epoch number: 391 and the loss: 198014.84375\n",
      "Epoch number: 401 and the loss: 197876.859375\n",
      "Epoch number: 411 and the loss: 197729.78125\n",
      "Epoch number: 421 and the loss: 197594.125\n",
      "Epoch number: 431 and the loss: 197423.484375\n",
      "Epoch number: 441 and the loss: 197288.390625\n",
      "Epoch number: 451 and the loss: 197174.90625\n",
      "Epoch number: 461 and the loss: 196959.015625\n",
      "Epoch number: 471 and the loss: 196885.046875\n",
      "Epoch number: 481 and the loss: 196704.640625\n",
      "Epoch number: 491 and the loss: 196514.0\n"
     ]
    }
   ],
   "source": [
    "epochs=500\n",
    "final_losses=[]\n",
    "for i in range(epochs):\n",
    "    i=i+1\n",
    "    y_pred=model(train_categorical,train_cont)\n",
    "    loss=torch.sqrt(loss_function(y_pred,y_train))\n",
    "    final_losses.append(loss)\n",
    "    if i%10==1:\n",
    "        print(\"Epoch number: {} and the loss: {}\".format(i,loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(epochs),final_losses)\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 187075.109375\n"
     ]
    }
   ],
   "source": [
    "y_pred=\"\"\n",
    "with torch.no_grad():\n",
    "    y_pred=model(test_categorical,test_cont)\n",
    "    loss=torch.sqrt(loss_function(y_pred,y_test))\n",
    "print('RMSE: {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "torch.save(model,'Houseprice.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'Houseweights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "embs_size=[(15,8),(5,3),(2,1),(4,2)]\n",
    "model1=FeedForwardNN(embs_size,5,1,[100,50],p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_11408\\4197685573.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1.load_state_dict(torch.load('Houseweights.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('Houseweights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
